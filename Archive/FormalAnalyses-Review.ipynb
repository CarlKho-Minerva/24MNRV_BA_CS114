{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS50 and CS51 Review\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CS50: Introduction to Computer Science ---\n",
    "\n",
    "## Session 1 (1.1): Critical Thinking\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Critical thinking** involves analyzing information objectively, identifying assumptions, evaluating evidence, and forming judgments. \n",
    "* It's about **questioning everything**, not just accepting information at face value.\n",
    "\n",
    "### Quantitative Notes\n",
    "* **No direct quantitative applications** in this introductory session. \n",
    "* However, critical thinking forms the foundation for analyzing data and drawing accurate conclusions in later sessions.\n",
    "\n",
    "## Session 2 (1.2): Logical Sentences\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Logical sentences** are statements that can be either true or false. \n",
    "* We use **propositions** (statements represented by letters) to build logical sentences.\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Truth values:**\n",
    "    *  True (T)\n",
    "    *  False (F)\n",
    "* **Example:**\n",
    "    * Proposition: \"It is raining.\" (Let's represent this with the letter 'R')\n",
    "    * If it's raining, R is True (T). If it's not raining, R is False (F).\n",
    "\n",
    "## Session 3 (2.1): Logical Connectives and Truth Tables\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Logical connectives** combine logical sentences:\n",
    "    * **AND (∧):** True only if both statements are true.\n",
    "    * **OR (∨):** True if at least one statement is true.\n",
    "    * **NOT (¬):** Reverses the truth value of a statement.\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Truth tables** systematically list all possible truth values for logical sentences.\n",
    "* **Example:**\n",
    "    * P: \"It is sunny.\"\n",
    "    * Q: \"It is warm.\"\n",
    "    * P ∧ Q (Sunny AND Warm) is true only if both P and Q are true.\n",
    "\n",
    "| P | Q | P ∧ Q |\n",
    "|---|---|-------|\n",
    "| T | T | T     |\n",
    "| T | F | F     |\n",
    "| F | T | F     |\n",
    "| F | F | F     |\n",
    "\n",
    "## Session 4 (2.2): De Morgan's Laws\n",
    "\n",
    "### Qualitative Notes\n",
    "* **De Morgan's Laws** provide rules for negating compound logical sentences:\n",
    "    * ¬(P ∧ Q) is logically equivalent to (¬P) ∨ (¬Q)\n",
    "    * ¬(P ∨ Q) is logically equivalent to (¬P) ∧ (¬Q)\n",
    "* They are essential for simplifying complex logical expressions.\n",
    "\n",
    "### Quantitative Notes\n",
    "* You can verify De Morgan's Laws using truth tables. \n",
    "* **Example:** \n",
    "    * ¬(\"It is sunny\" AND \"It is warm\") is the same as (\"It is not sunny\" OR \"It is not warm\").\n",
    "\n",
    "## Session 5 (3.1): Deductive Validity\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Deductive validity:** An argument is deductively valid if the conclusion logically follows from the premises (the statements given).\n",
    "* If the premises are true and the argument is valid, the conclusion *must* be true.\n",
    "\n",
    "### Quantitative Notes\n",
    "* No direct numerical calculations are involved.\n",
    "* **Example:**\n",
    "    * Premise 1: All dogs are mammals.\n",
    "    * Premise 2: Fido is a dog.\n",
    "    * Conclusion: Fido is a mammal. (This argument is deductively valid) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... (Previous Code) ...\n",
    "\n",
    "## Session 6 (3.2): Induction\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Induction** involves making generalizations based on observed patterns.\n",
    "* **Strong vs. Weak Induction:**\n",
    "    * **Strong:** If a statement holds for all cases up to a certain point, it holds for the next case as well.\n",
    "    * **Weak:** Draws a general conclusion from a limited number of observations.\n",
    "\n",
    "### Quantitative Notes\n",
    "* Often used in mathematical proofs and algorithms.\n",
    "* **Example (Weak Induction):** You observe 100 swans, and they are all white. You might conclude that all swans are white (though this is not necessarily true).\n",
    "\n",
    "## Session 7 (4.1): Fallacy Detection\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Fallacies** are errors in reasoning that make arguments invalid.\n",
    "* Common Fallacies:\n",
    "    * **Ad hominem:** Attacking the person instead of the argument.\n",
    "    * **Straw man:** Misrepresenting the opponent's argument.\n",
    "    * **False dilemma:** Presenting only two options when more exist.\n",
    "\n",
    "### Quantitative Notes\n",
    "* No direct quantitative aspects, but recognizing fallacies is crucial for interpreting data and statistical claims. \n",
    "* **Example:** \"You can't trust their study on climate change; they are funded by an oil company\" (ad hominem fallacy).\n",
    "\n",
    "## Session 8 (4.2): Logic Synthesis\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Logic synthesis** involves combining basic logical elements (gates) to create more complex circuits.\n",
    "* Fundamental to computer science, as it forms the basis of how computers process information.\n",
    "\n",
    "### Quantitative Notes\n",
    "* Boolean algebra is used to represent and manipulate logical expressions.\n",
    "* **Truth tables** are essential tools in logic synthesis. \n",
    "* **Example:** Designing a logic circuit that outputs True only when two input signals are both True (this would be an AND gate).\n",
    "\n",
    "## Session 9 (5.1): Estimation: Fermi Problems\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Fermi problems** involve making order-of-magnitude estimations for quantities that seem difficult or impossible to calculate directly.\n",
    "* Focus on breaking down the problem into smaller, more manageable parts.\n",
    "\n",
    "### Quantitative Notes\n",
    "* Emphasizes using approximations and back-of-the-envelope calculations.\n",
    "* **Example:** Estimate the number of piano tuners in Chicago. You might consider the population of Chicago, the percentage of people who own pianos, how often pianos need tuning, etc. \n",
    "\n",
    "## Session 10 (5.2): Variables\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Variables** are symbols that represent values that can change within a program or calculation.\n",
    "* Essential for storing and manipulating data.\n",
    "\n",
    "### Quantitative Notes\n",
    "* Variables can store various data types:\n",
    "    * **Integers (int):** Whole numbers (e.g., 5, -10, 1000)\n",
    "    * **Floats (float):** Numbers with decimal points (e.g., 3.14, -2.5, 10.0)\n",
    "    * **Strings (str):** Text (e.g., \"hello\", \"CS50\")\n",
    "* **Example:**\n",
    "```python\n",
    "x = 10 # Assign the value 10 to the variable 'x'\n",
    "y = 3.14 # Assign 3.14 to 'y'\n",
    "name = \"Alice\" # Assign the string \"Alice\" to 'name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... (Previous Code) ...\n",
    "\n",
    "## Session 11 (6.2): Descriptive Statistics\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Descriptive statistics** summarize and visualize data to reveal patterns and insights.\n",
    "* **Measures of central tendency:**\n",
    "    * **Mean:** Average value.\n",
    "    * **Median:** Middle value when data is ordered.\n",
    "    * **Mode:** Most frequent value.\n",
    "* **Measures of dispersion:**\n",
    "    * **Range:** Difference between the highest and lowest values.\n",
    "    * **Variance:** Average squared deviation from the mean.\n",
    "    * **Standard deviation:** Square root of the variance (measures spread).\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Example:** Consider the following dataset of exam scores: [75, 80, 85, 90, 95]\n",
    "    * Mean: 85\n",
    "    * Median: 85\n",
    "    * Range: 20\n",
    "    * Standard deviation: ≈ 7.07\n",
    "* **Visualizations:** Histograms, box plots, scatter plots.\n",
    "\n",
    "## Session 12 (7.1): Probability Rules and Interpretations\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Probability** quantifies the likelihood of an event occurring.\n",
    "* **Probability scale:** Ranges from 0 (impossible) to 1 (certain).\n",
    "* **Basic probability rules:**\n",
    "    * Sum rule: P(A or B) = P(A) + P(B) - P(A and B)\n",
    "    * Complement rule: P(not A) = 1 - P(A)\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Example:**\n",
    "    * If you roll a fair six-sided die, the probability of rolling a 4 is 1/6.\n",
    "    * The probability of rolling an even number is 1/2 (2, 4, or 6).\n",
    "\n",
    "## Session 13 (7.2): Conditional Probability\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Conditional probability** is the probability of an event happening given that another event has already occurred.\n",
    "* Notation: P(A|B) represents the probability of event A given event B.\n",
    "\n",
    "### Quantitative Notes\n",
    "* Formula: P(A|B) = P(A and B) / P(B)\n",
    "* **Example:** \n",
    "    * A bag contains 3 red balls and 2 blue balls.\n",
    "    * Event A: Drawing a red ball.\n",
    "    * Event B: Drawing a blue ball on the first draw (without replacement).\n",
    "    * P(A|B) = (3/4) * (2/3) / (2/5) = 5/8 (The probability of drawing a red ball given that a blue ball was drawn first)\n",
    "\n",
    "## Session 14 (8.1): Distributions of Discrete Random Variables\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Random variable:** A variable whose value is a numerical outcome of a random phenomenon.\n",
    "* **Discrete random variable:** Can only take on a finite number of values.\n",
    "* **Probability distribution:** Assigns probabilities to each possible value of the random variable.\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Common discrete distributions:**\n",
    "    * Bernoulli: Models the probability of success or failure in a single trial.\n",
    "    * Binomial: Models the probability of a certain number of successes in a fixed number of trials.\n",
    "    * Poisson: Models the probability of a certain number of events occurring in a fixed interval of time or space.\n",
    "\n",
    "## Session 15 (8.2): Probability, Distributions, and Simulations\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Simulations** use random numbers and computational models to mimic real-world processes.\n",
    "* Useful for estimating probabilities and understanding complex systems when analytical solutions are difficult.\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Monte Carlo simulations** are a common type that involve repeated random sampling.\n",
    "* **Example:** Simulating coin flips to estimate the probability of getting a certain number of heads in a row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... (Previous Code) ...\n",
    "\n",
    "## Session 16 (9.1): The Normal Distribution\n",
    "\n",
    "### Qualitative Notes\n",
    "* The **normal distribution** (bell curve) is a fundamental probability distribution in statistics.\n",
    "* Characterized by its mean (μ) and standard deviation (σ).\n",
    "* **68-95-99.7 rule:** \n",
    "    * Approximately 68% of data falls within 1 standard deviation of the mean.\n",
    "    * 95% within 2 standard deviations.\n",
    "    * 99.7% within 3 standard deviations.\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Probability density function (PDF):** Describes the probability of a continuous random variable falling within a given range.\n",
    "* **Example:** Heights, IQ scores, and many natural phenomena often follow a normal distribution.\n",
    "\n",
    "## Session 17 (9.2): Sampling Distributions and the Central Limit Theorem\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Sampling distribution:** The distribution of a statistic (e.g., the mean) calculated from multiple random samples.\n",
    "* **Central Limit Theorem (CLT):**  As sample size increases, the sampling distribution of the sample mean approaches a normal distribution, regardless of the shape of the original population distribution.\n",
    "\n",
    "### Quantitative Notes\n",
    "* CLT is crucial for making inferences about populations based on samples.\n",
    "* **Example:** If you repeatedly sample from a population (even if it's not normally distributed) and calculate the mean of each sample, the distribution of those sample means will start to look normal as the sample size gets larger.\n",
    "\n",
    "## Session 18 (10.1): CLT Continued and Regression to the Mean\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Regression to the mean:** Extreme values in a dataset tend to be followed by values closer to the average.\n",
    "* Explained by random variation and the tendency for extreme events to be less likely.\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Example:**  A student who scores very high on one exam is likely to score slightly lower on the next exam, simply due to random variation. \n",
    "\n",
    "## Session 19 (10.2): Confidence Intervals for Means with the Normal Distribution\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Confidence interval:** A range of values within which we are confident that a population parameter (e.g., the mean) lies.\n",
    "* Expressed with a confidence level (e.g., 95% confident).\n",
    "* Wider intervals indicate more uncertainty.\n",
    "\n",
    "### Quantitative Notes\n",
    "* Formula (for a 95% confidence interval of the mean, assuming a normal distribution):\n",
    "    *  `Confidence Interval = sample_mean ± (1.96 * standard_error)` \n",
    "    *  `standard_error = sample_standard_deviation / sqrt(sample_size)`\n",
    "* **Example:**  If a 95% confidence interval for the average height of a group is 160cm to 170cm, we are 95% confident that the true average height falls within this range.\n",
    "\n",
    "## Session 20 (11.1): Confidence Intervals for Means with the T-Distribution and Sampling Independently\n",
    "\n",
    "### Qualitative Notes\n",
    "* **T-distribution:** Similar to the normal distribution, but used when the population standard deviation is unknown, and the sample size is small.\n",
    "* **Degrees of freedom:** A parameter of the t-distribution, related to the sample size. \n",
    "* **Independent sampling:** Observations in one sample do not influence observations in another.\n",
    "\n",
    "### Quantitative Notes\n",
    "* The t-distribution is wider and flatter than the normal distribution for smaller sample sizes, reflecting greater uncertainty.\n",
    "* **Example:**  Calculating a confidence interval for the average income of a small town when you don't know the population standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... (Previous Code) ...\n",
    "\n",
    "## Session 16 (9.1): The Normal Distribution\n",
    "\n",
    "### Qualitative Notes\n",
    "* The **normal distribution** (bell curve) is a fundamental probability distribution in statistics.\n",
    "* Characterized by its mean (μ) and standard deviation (σ).\n",
    "* **68-95-99.7 rule:** \n",
    "    * Approximately 68% of data falls within 1 standard deviation of the mean.\n",
    "    * 95% within 2 standard deviations.\n",
    "    * 99.7% within 3 standard deviations.\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Probability density function (PDF):** Describes the probability of a continuous random variable falling within a given range.\n",
    "* **Example:** Heights, IQ scores, and many natural phenomena often follow a normal distribution.\n",
    "\n",
    "## Session 17 (9.2): Sampling Distributions and the Central Limit Theorem\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Sampling distribution:** The distribution of a statistic (e.g., the mean) calculated from multiple random samples.\n",
    "* **Central Limit Theorem (CLT):**  As sample size increases, the sampling distribution of the sample mean approaches a normal distribution, regardless of the shape of the original population distribution.\n",
    "\n",
    "### Quantitative Notes\n",
    "* CLT is crucial for making inferences about populations based on samples.\n",
    "* **Example:** If you repeatedly sample from a population (even if it's not normally distributed) and calculate the mean of each sample, the distribution of those sample means will start to look normal as the sample size gets larger.\n",
    "\n",
    "## Session 18 (10.1): CLT Continued and Regression to the Mean\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Regression to the mean:** Extreme values in a dataset tend to be followed by values closer to the average.\n",
    "* Explained by random variation and the tendency for extreme events to be less likely.\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Example:**  A student who scores very high on one exam is likely to score slightly lower on the next exam, simply due to random variation. \n",
    "\n",
    "## Session 19 (10.2): Confidence Intervals for Means with the Normal Distribution\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Confidence interval:** A range of values within which we are confident that a population parameter (e.g., the mean) lies.\n",
    "* Expressed with a confidence level (e.g., 95% confident).\n",
    "* Wider intervals indicate more uncertainty.\n",
    "\n",
    "### Quantitative Notes\n",
    "* Formula (for a 95% confidence interval of the mean, assuming a normal distribution):\n",
    "    *  `Confidence Interval = sample_mean ± (1.96 * standard_error)` \n",
    "    *  `standard_error = sample_standard_deviation / sqrt(sample_size)`\n",
    "* **Example:**  If a 95% confidence interval for the average height of a group is 160cm to 170cm, we are 95% confident that the true average height falls within this range.\n",
    "\n",
    "## Session 20 (11.1): Confidence Intervals for Means with the T-Distribution and Sampling Independently\n",
    "\n",
    "### Qualitative Notes\n",
    "* **T-distribution:** Similar to the normal distribution, but used when the population standard deviation is unknown, and the sample size is small.\n",
    "* **Degrees of freedom:** A parameter of the t-distribution, related to the sample size. \n",
    "* **Independent sampling:** Observations in one sample do not influence observations in another.\n",
    "\n",
    "### Quantitative Notes\n",
    "* The t-distribution is wider and flatter than the normal distribution for smaller sample sizes, reflecting greater uncertainty.\n",
    "* **Example:**  Calculating a confidence interval for the average income of a small town when you don't know the population standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ... (Previous Code) ...\n",
    "\n",
    "## Session 21 (11.2): Hypothesis Tests for Single Means, Type I & II Errors\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Hypothesis test:** A statistical method for testing a claim about a population parameter.\n",
    "* **Null hypothesis (H0):** The default assumption we are trying to disprove.\n",
    "* **Alternative hypothesis (H1):**  The claim we are trying to find evidence for.\n",
    "* **Type I error:** Rejecting the null hypothesis when it's actually true (false positive).\n",
    "* **Type II error:** Failing to reject the null hypothesis when it's actually false (false negative).\n",
    "\n",
    "### Quantitative Notes\n",
    "* **P-value:**  The probability of observing data as extreme as ours if the null hypothesis were true. \n",
    "    * Low p-value (typically < 0.05) leads to rejecting the null hypothesis.\n",
    "* **Example:**  Testing whether a new drug lowers blood pressure more effectively than a placebo.\n",
    "\n",
    "## Session 22 (13.1): Hypothesis Tests, Confidence Intervals, and Multiple Comparisons\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Connection between CI and hypothesis tests:** If a 95% CI for the difference between two groups doesn't contain 0, it suggests a statistically significant difference (we would reject the null hypothesis of no difference).\n",
    "* **Multiple comparisons problem:** When conducting multiple hypothesis tests, the chance of a Type I error (false positive) increases.\n",
    "* **Corrections (e.g., Bonferroni):** Methods for adjusting p-values to account for multiple comparisons. \n",
    "\n",
    "### Quantitative Notes\n",
    "* It's essential to choose an appropriate hypothesis test based on the data and research question. \n",
    "* **Example:** Testing the effectiveness of different marketing campaigns on website traffic requires adjusting for multiple comparisons.\n",
    "\n",
    "## Session 23 (13.2): Difference of Means Tests and Effect Size\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Difference of means tests:** Used to determine if there's a significant difference between the means of two groups.\n",
    "* **Independent samples t-test:** For independent groups.\n",
    "* **Paired samples t-test:** For related groups (e.g., before-and-after measurements).\n",
    "* **Effect size:**  Measures the magnitude of the difference between groups (not just whether it's statistically significant).\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Cohen's d** is a common effect size measure for the difference of means.\n",
    "* **Example:** A large effect size indicates a substantial practical difference between groups, even if the p-value is small.\n",
    "\n",
    "## Session 24 (14.1): Effect Size and Statistical Power\n",
    "\n",
    "### Qualitative Notes\n",
    "* **Statistical power:** The probability of correctly rejecting the null hypothesis when it is false (finding a real effect).\n",
    "* Power is influenced by:\n",
    "    * Effect size: Larger effects are easier to detect.\n",
    "    * Sample size: Larger samples provide more power.\n",
    "    * Significance level (alpha): Smaller alpha reduces power (more conservative). \n",
    "\n",
    "### Quantitative Notes\n",
    "* Power analysis is used to determine the required sample size to achieve a desired level of power.\n",
    "* **Example:**  A study with low power might fail to detect a real difference between groups due to insufficient sample size.\n",
    "\n",
    "## Session 25 (14.2): Review and Synthesis: All HCs\n",
    "\n",
    "### Qualitative Notes\n",
    "* Final review of key concepts and connections between them.\n",
    "* Emphasizes the application of statistical thinking to real-world problems.\n",
    "\n",
    "### Quantitative Notes\n",
    "* **Example:**  You would synthesize your understanding of hypothesis testing, confidence intervals, effect size, and power to design and interpret a research study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
